## 线性代数

### 向量
#### 张成空间
张成空间是向量 $v$ 和 $w$ 全部线性组合构成的向量集合，即：
$$av + bw ( a, b 在实数范围内变动)$$
#### 向量空间的基
向量空间中的一组基是张成该空间的一个线性无关向量的集合。该向量空间的任意一个向量都可以用这组基向量的线性组合表示。
#### 向量空间的维度
空间的维数可以通过基向量的个数来定义    
维数 = 基向量的个数 = 坐标的分量数
#### 向量的点积
点乘，也叫向量的内积、数量积。顾名思义，求下来的结果是一个数。两个维度相同的向量，点积定义为两个向量对应位的元素相乘，并将所有结果加和。
两个向量$v$和$u$的点积可以理解为：$v$向$u$的投影长度与$u$长度的乘积
<!-- $$
\left[
\begin{matrix}
2\\
5\\
3
\end{matrix}
\right]
$$ -->

点积有如下特点：
- 两个向量互相垂直时，点积为0
- 两个向量方向相同时，点积为正，相反时，点积为负


### 矩阵
矩阵的本质是 **映射，或者说是向量运动的描述**   
将$n$维向量$x$乘以$m * n$ 矩阵 $A$，能得到一个$m$维向量$y = Ax$，也就是说，指定了矩阵 $A$1 ，就确定了从向量到另外一个向量的映射。

#### 列空间
矩阵 $A$ 的列空间为所有可能的输出向量 $Av$ 构成的集合，换句话说，列空间就是矩阵所有的列所张成的空间。    
所以更精确的秩的定义是列空间的维数；当秩达到最大值时，意味着秩和列数相等，也即满秩。

#### 行列式
矩阵线性变换的行列式即线性变换改变面积的比例。
$$
det(M_{1}M_{2}) = det(M_{1})det(M_{2})
$$
- **检验一个矩阵的行列式是否为0，就能了解这个矩阵所代表的变换是否将空间压缩到更小的维度上**
- 在三维空间下，行列式可以简单看作这个平行六面体的体积，行列式为0则意味着整个空间被压缩为零体积的东西，也就是一个平面或者一条直线，或者更极端情况下的一个点
- 行列式的值可以为负，代表空间定向发生了改变（翻转）；但是行列式的绝对值依然表示区域面积的缩放比例

#### 奇异矩阵
行列式为零的矩阵被称为奇异矩阵，从行列式为零的定义可以知道，奇异矩阵是一种将当前维度空间压缩到了更小维度空间的线性变换。



### 矩阵分解
#### 特征值和特征向量
如果一个向量$v$是方阵$A$的特征向量，则以下等式成立：
$$
Av = \lambda v
$$
其中，$\lambda$为向量$v$对应的特征值。

特征分解是将一个矩阵分解为如下形式：
$$
A = Q \sum Q^{-1}
$$
其中$Q$是这个矩阵的特征向量组成的矩阵，$\sum$是一个对角矩阵，对角线上的每个元素是一个特征值。里面的特征值是由大到小排列的，这些特征值所对应的特征向量就是描述这个矩阵变化方向（从主要的变化到次要的变化排列）。也就是说矩阵A的信息可以由其特征值和特征向量表示。

对于矩阵为高维的情况下，那么这个矩阵就是高维空间下的一个线性变换。可以想象，这个变换也同样有很多的变换方向，我们通过特征值分解得到的前N个特征向量，那么就对应了这个矩阵最主要的N个变化方向。我们利用这前N个变化方向，就可以近似这个矩阵（变换）。

总结一下，特征值分解可以得到特征值与特征向量，特征值表示的是这个特征到底有多重要，而特征向量表示这个特征是什么。不过，特征值分解也有很多的局限，比如说变换的矩阵必须是方阵。

#### 奇异值分解
特征值分解是一个提取矩阵特征很不错的方法，但是它只是对方阵而言的，在现实的世界中，我们看到的大部分矩阵都不是方阵，比如说有N个学生，每个学生有M科成绩，这样形成的一个N * M的矩阵就不可能是方阵，我们怎样才能描述这样普通的矩阵呢的重要特征呢？奇异值分解可以用来干这个事情，奇异值分解是一个能适用于任意的矩阵的一种分解的方法：
$$
A_{m*n} = U_{m*m} \sum V^{T}_{n*n}
$$
假设A是一个M * N的矩阵，那么得到的U是一个M * M的方阵（称为左奇异向量），Σ是一个M * N的矩阵（除了对角线的元素都是0，对角线上的元素称为奇异值），VT(V的转置)是一个N * N的矩阵（称为右奇异向量）。

#### LU分解
给定矩阵A，将A表示成下三角矩阵L和上三角矩阵U的乘积，称为LU分解。
