{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFlayers\n",
    "tf.layers模块是对TensorFlow更高层次封装的API，使用它我们可以更加轻松的构建模型\n",
    "## 常用函数\n",
    "- input(…): 用于实例化一个输入 Tensor，作为神经网络的输入。\n",
    "- average_pooling1d(…): 一维平均池化层\n",
    "- average_pooling2d(…): 二维平均池化层\n",
    "- average_pooling3d(…): 三维平均池化层\n",
    "- batch_normalization(…): 批量标准化层\n",
    "- conv1d(…): 一维卷积层\n",
    "- conv2d(…): 二维卷积层\n",
    "- conv2d_transpose(…): 二维反卷积层\n",
    "- conv3d(…): 三维卷积层\n",
    "- conv3d_transpose(…): 三维反卷积层\n",
    "- dense(…): 全连接层\n",
    "- dropout(…): Dropout层\n",
    "- flatten(…): Flatten层，即把一个 Tensor 展平\n",
    "- max_pooling1d(…): 一维最大池化层\n",
    "- max_pooling2d(…): 二维最大池化层\n",
    "- max_pooling3d(…): 三维最大池化层\n",
    "- separable_conv2d(…): 二维深度可分离卷积层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.layers.input() 该模块已被删除\n",
    "这个方法是用于输入数据的方法，其实类似于 tf.placeholder，相当于一个占位符的作用，当然也可以通过传入 tensor 参数来进行赋值。\n",
    "```\n",
    "tf.layers.input(\n",
    "    shape=None,\n",
    "    batch_size=None,\n",
    "    name=None,\n",
    "    dtype=tf.float32,\n",
    "    sparse=False,\n",
    "    tensor=None\n",
    ")\n",
    "```\n",
    "注意：该方法会对输入的shape进行转化，比如说本来是 [32]，它会转化为 [?, 32]，即第一维代表 batch_size，所以我们需要注意，在调用此方法的时候不需要去关心 batch_size 这一维。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.layers.batch_normalization(inputs, ...)\n",
    "批量标准化的方法，经过处理之后可以加速训练速度\n",
    "\n",
    "直接在输入数据后面加一层batch_normalization()即可\n",
    "```\n",
    "x = tf.layers.Input(shape=[32])\n",
    "x = tf.layers.batch_normalization(x)\n",
    "y = tf.layers.dense(x, 20)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.layers.dense()\n",
    "全连接网络，layers 模块提供了一个 dense() 方法来实现此操作\n",
    "```\n",
    "dense(\n",
    "    inputs,  #输入数据（必须）\n",
    "    units,   #神经元数量（必须）\n",
    "    activation=None, #可选，设定激活函数\n",
    "    use_bias=True, #是否使用偏置项\n",
    "    kernel_initializer=None,\n",
    "    bias_initializer=tf.zeros_initializer(),\n",
    "    kernel_regularizer=None,  #可选，对权重weight进行正则化\n",
    "    bias_regularizer=None,    #可选，对bias进行正则化\n",
    "    activity_regularizer=None, #输出正则化\n",
    "    kernel_constraint=None,\n",
    "    bias_constraint=None,\n",
    "    trainable=True,\n",
    "    name=None,\n",
    "    reuse=None\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.layers.convolution\n",
    "layers提供了多个卷积方法，如 conv1d()、conv2d()、conv3d()，分别代表一维、二维、三维卷积，另外还有 conv2d_transpose()、conv3d_transpose()，分别代表二维和三维反卷积，还有 separable_conv2d() 方法代表二维深度可分离卷积。其用法都是类似的，在这里以 conv2d() 方法为例进行说明。\n",
    "```\n",
    "conv2d(\n",
    "    inputs, #必须，进行卷积操作的输入 [batch, hight, weight, channels]\n",
    "    filters, #必须，int值，代表输出通道的个数，即output_channels\n",
    "    kernel_size, #必须，卷积核大小，int值时表示kernel的高宽都是这个值，或者是长度为2的list分别代表高和宽\n",
    "    strides=(1, 1), #strides\n",
    "    padding='valid', #不区分大小写的padding，vaild和same两种格式\n",
    "    data_format='channels_last',\n",
    "    dilation_rate=(1, 1),\n",
    "    activation=None, #激活函数\n",
    "    use_bias=True,\n",
    "    kernel_initializer=None,\n",
    "    bias_initializer=tf.zeros_initializer(),\n",
    "    kernel_regularizer=None,\n",
    "    bias_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    kernel_constraint=None,\n",
    "    bias_constraint=None,\n",
    "    trainable=True,\n",
    "    name=None,\n",
    "    reuse=None\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.layers.pooling\n",
    "layers 模块提供了多个池化方法，这几个池化方法都是类似的，包括 max_pooling1d()、max_pooling2d()、max_pooling3d()、average_pooling1d()、average_pooling2d()、average_pooling3d()，分别代表一维二维三维最大和平均池化方法， max_pooling2d() 函数签名如下\n",
    "```\n",
    "max_pooling2d(\n",
    "    inputs,#必需，即需要池化的输入对象，必须是 4 维的。\n",
    "    pool_size,#必需，池化窗口大小，必须是一个数字（高和宽）或者长度为 2 的列表（分别代表高、宽）。\n",
    "    strides,#必需，池化步长，必须是一个数字（高和宽都是此数字）或者长度为 2 的列表（分别代表高、宽）\n",
    "    padding='valid',\n",
    "    data_format='channels_last',\n",
    "    name=None\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.layers.dropout\n",
    "对输入tensor进行dropout\n",
    "```\n",
    "dropout(\n",
    "    inputs,#必须，即输入数据。\n",
    "    rate=0.5,#可选，默认为 0.5，即 dropout rate，如设置为 0.1，则意味着会丢弃 10% 的神经元。\n",
    "    noise_shape=None,\n",
    "    seed=None,\n",
    "    training=False,\n",
    "    name=None\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.layers.flatten\n",
    "flatten() 方法可以对 Tensor 进行展平操作\n",
    "```\n",
    "flatten(\n",
    "    inputs,\n",
    "    name=None\n",
    ")#返回结果： 展平后的 Tensor。\n",
    "```\n",
    "\n",
    "假设输入数据的 shape 为 [?, 5, 6]，经过 flatten 层之后，就会变成 [?, 30]，即将除了第一维的数据维度相乘，对原 Tensor 进行展平。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "x = tf.keras.Input(shape=[20, 20, 3])\n",
    "conv_layer = tf.layers.conv2d(x, filters=6, kernel_size=3, strides=[1,1], padding='same', activation='relu')\n",
    "maxpool_layer = tf.layers.max_pooling2d(conv_layer, pool_size=2, strides=2)\n",
    "flatten_layer = tf.layers.flatten(maxpool_layer)\n",
    "fc_layer1 = tf.layers.dense(flatten_layer, units=1024, activation='relu')\n",
    "fc_layer1 = tf.layers.dropout(fc_layer1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
